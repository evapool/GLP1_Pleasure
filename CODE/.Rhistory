df_dict <- data.frame(variable = biomed, out_low = rep(-3,length(biomed)),  out_high = rep(3,length(biomed)))
for (var in df_dict$variable) {
METAB[[var]][METAB[[var]] < df_dict[df_dict$variable == var, ]$out_low | METAB[[var]] > df_dict[df_dict$variable == var, ]$out_high] <- NaN}
ALL = join(BEHAV, METAB, by = "id")
# exclude participant that did not do two sessions
ALL = subset (ALL, id != "201" &
id != "208" &
id != "210" &
id != "214" &
id != "214" &
id != "216" &
id != "219" &
id != "222" &
id != "223" &
id != "233" &
id != "234" &
id != "240" &
id != "245" &
id != "247" &
id != "249" &
id != "258" &
id != "263" &
id != "267"
)
# remove participant that do not have fmri data
ALL = subset (ALL, id != "226" &
id != "228" &
id != "234" &
id != "242"
)
fac <- c("id", "trial", "condition", "session", "intervention", "gender"); ALL[fac] <- lapply(ALL[fac], factor)
# recode to be interpretable
ALL$gender  <- dplyr::recode(ALL$gender, "0" = "Female", "1" = "Male" )
ALL$intervention <- dplyr::recode(ALL$intervention, "0" = "Placebo", "1" = "Liraglutide" )
HED.means <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$condition, ALL$session, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(HED.means) <- c('id','condition','session', 'intervention','perceived_liking')
HED.trial <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$trialxcondition, ALL$condition, ALL$session, ALL$intervention), FUN='mean') # extract means
colnames(HED.trial) <- c('id',"trialxcondition",'condition',"session","intervention","perceived_liking")
df.demo <- aggregate(ALL$bmi1, by = list(ALL$id, ALL$ageF, ALL$BW_V1, ALL$WC_V1, ALL$gender, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.demo) <- c('id','age',"body weight", "waist circumference",'gender', 'intervention','BMI')
table_demo <- egltable(c("BMI", "age", "body weight", "waist circumference", "gender"),
g = "intervention", data = df.demo, strict = FALSE) %>%
kbl(caption ="Demografics of Trial Population Before Intervetion", digits = 2) %>%
kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
row_spec(0,bold=T,align='c')
pdf(file.path(figures_path,'Table_Demografics.pdf'))
dev.off()
# exclude participant that did not do two sessions
METAB2  = subset (METAB2 , id != "201" & id != "200" &
id != "208" &
id != "210" &
id != "214" &
id != "214" &
id != "216" &
id != "219" &
id != "222" &
id != "223" &
id != "233" &
id != "234" &
id != "240" &
id != "245" &
id != "247" &
id != "249" &
id != "258" &
id != "263" &
id != "267")
# remove participant that do not have fmri data
METAB2 = subset (METAB2 , id != "226" &  id != "228" &  id != "234" & id != "242" & id != "212" & id != "264")
meta.subscale <- c("id","BMI_diff", "BW_diff", "WC_diff", "intervention", "Insulin_diff", "Glu_diff",
"SPB_diff","DBP_diff","HR_diff", "ChTot_diff","HDL_diff", "LDL_diff","TG_diff",
"HBA1c_diff")
df.meta <- METAB2[meta.subscale]
colnames(df.meta) <- c('id','BMI',"body weight", "waist circumference", 'intervention',
'insuline','gluca','systolic blood pressure', 'diastolic blood pressure',
'heart rate', 'total cholesterol',# missing leptin and adiopecin # restini #obestatin
'HDL cholesterol', 'LDL cholesterol','Triglycerides','HbA1c')
meta.variables <- c('BMI',"body weight", "waist circumference",
'insuline','gluca','systolic blood pressure', 'diastolic blood pressure',
'heart rate', 'total cholesterol',# missing leptin and adiopecin # restini #obestatin
'HDL cholesterol', 'LDL cholesterol','Triglycerides','HbA1c')
table_medic <- egltable(meta.variables, g = "intervention", data = df.meta, strict = FALSE) %>%
kbl(caption ="Change in secondary end points from baseline to 16-week follow-up", digits = 2) %>%
kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
row_spec(0,bold=T,align='c')
pdf(file.path(figures_path,'Table_Medical.pdf'))
dev.off()
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
#---------------------------------------------------- define statstical Model
mf = formula(BMI_diff ~ intervention + gender + age  + (1|id))
#---------------------------------------------------- run frequenstistic stat
fmod_weight = lm(update(mf, ~.- (1|id)) , data = df.weight)
anova(fmod_weight)
summary(fmod_weight)
df.weight$gender <- ifelse(df.weight$gender==0,-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$intervention <- ifelse(df.weight$intervention==0,-1,df.weight$intervention)  #SUM-CODING HERE!
#---------------------------------------------------- run frequenstistic stat
fmod_weight = lm(update(mf, ~.- (1|id)) , data = df.weight)
summary(fmod_weight)
#---------------------------------------------------- define statstical Model
mf = formula(BMI_diff ~ intervention + gender + age  + (1|id))
#---------------------------------------------------- run frequenstistic stat
fmod_weight = lm(update(mf, ~.- (1|id)) , data = df.weight)
anova(fmod_weight)
summary(fmod_weight)
confint(fmod_weight, level = 0.95, method = "Wald")
full_tab_weight
bmod_weight
#---------------------------------------------------- run baysian stat
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 40000
bmod_weight = brm(BMI_diff ~ intervention + gender + age, data=df.weight, family = gaussian,
prior = c(prior(normal(0,1), class = "b")),
sample_prior=TRUE, chains=4,
iter=niter, warmup=1000, seed=123, backend="cmdstanr",
control = list(adapt_delta = 0.99))
bmod_weight
# save model so that we do not have to run it evertime
save (bmod_weight, file = file.path(analysis_path, 'Bmod_weight.R'))
# extract BF
full_tab_weight = describe_posterior(bmod_weight, estimate = "median",
dispersion = T, ci = .9, ci_method = "hdi",
bf_prior = bmod_weight, diagnostic = "Rhat",
test = c("p_direction", "bf"))
# bayesian interpretation of the results (for intervetion)
report = capture.output(sexit(bmod_weight, ci=.9))
full_tab_weight
# non normalized body weight for plots
ALL$BMI_Diff_raw = ALL$bmi1 - ALL$BMI_V10
df.weight <- aggregate(ALL$BMI_Diff_raw, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_Diff_raw')
# compute mean and se
weight.pp <- summarySE(df.weight,
measurevar = c("BMI_Diff_raw"),
groupvars = "intervention")
# plot
p_weight = ggplot(df.weight, aes(x = intervention, y = BMI_Diff_raw, fill = intervention, color = intervention)) +
geom_abline(slope=0, intercept=0, linetype = "dashed", color = "black") +
geom_flat_violin(scale = "count", trim = FALSE, alpha = .1, aes(fill = intervention, color = NA), color = NA) +
geom_point(aes(group = id, y = BMI_Diff_raw), alpha = .3, position = position_dodge(0.2), size = 0.5) +
geom_crossbar(data = weight.pp, aes(y = BMI_Diff_raw, ymin=BMI_Diff_raw-se, ymax=BMI_Diff_raw+se), width = 0.5 , alpha = 0.1) +
ylab('Weight Loss [BMI post - BMI pre]') +
xlab('Intervention') +
scale_fill_manual(values=c("Placebo"= pal[1], "Liraglutide"=pal[3]), guide = 'none') +
scale_color_manual(values=c("Placebo"=pal[1], "Liraglutide"=pal[3]), guide = 'none') +
theme_bw()
# save plot
p_weight + timeline_theme
HED.aov     <- aov_car(perceived_liking ~ trialxcondition + Error (id/trialxcondition), data = HED.trial, anova_table = list(correction = "GG", es = "pes"))
HED.emm    <- emmeans(HED.aov, ~ trialxcondition , model = "multivariate")
HED.linear  <- contrast(HED.emm, "poly") # look only at the linear constrast here
coef(HED.linear)
HED.trial$saturation = scales::rescale(as.numeric(HED.trial$trialxcondition), to = c(19,-19))
HED.trial$perceived_liking_z = scale(HED.trial$perceived_liking) # so that the prior are scaled correctly
mf = formula(perceived_liking_z ~ condition*session*intervention*saturation + (condition*session*saturation|id))
HED.trial$intervention
HED.trial$intervention <- ifelse(HED.trial$intervention==0,-1,df.weight$intervention)  #SUM-CODING HERE!
mf = formula(perceived_liking_z ~ condition*session*intervention*saturation + (condition*session*saturation|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.trial, control = my_control)
anova(fmod_like,type=2)
summary(fmod_like)
HED.trial <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$trialxcondition, ALL$condition, ALL$session, ALL$intervention), FUN='mean') # extract means
colnames(HED.trial) <- c('id',"trialxcondition",'condition',"session","intervention","perceived_liking")
HED.aov     <- aov_car(perceived_liking ~ trialxcondition + Error (id/trialxcondition), data = HED.trial, anova_table = list(correction = "GG", es = "pes"))
HED.emm    <- emmeans(HED.aov, ~ trialxcondition , model = "multivariate")
HED.linear  <- contrast(HED.emm, "poly") # look only at the linear constrast here
coef(HED.linear)
HED.trial$saturation = scales::rescale(as.numeric(HED.trial$trialxcondition), to = c(19,-19))
HED.trial$perceived_liking_z = scale(HED.trial$perceived_liking) # so that the prior are scaled correctly
mf = formula(perceived_liking_z ~ condition*session*intervention*saturation + (condition*session*saturation|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.trial, control = my_control)
anova(fmod_like,type=2)
summary(fmod_like)
confint(fmod_like, level = 0.95, method = "Wald")
HED.trial$intervention <- ifelse(HED.trial$intervention==0,-1,df.trialt$intervention)  #SUM-CODING HERE!
HED.trial$intervention <- ifelse(HED.trial$intervention==0,-1,df.trial$intervention)  #SUM-CODING HERE!
HED.trial$intervention <- ifelse(HED.trial$intervention==0,-1,HED.trial$intervention)  #SUM-CODING HERE!
mf = formula(perceived_liking_z ~ condition*session*intervention*saturation + (condition*session*saturation|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.trial, control = my_control)
HED.trial$intervention
View(HED.trial)
View(HED.means)
View(HED.trial)
View(df.weight)
df.weight$intervention <- ifelse(df.weight$intervention==0,-1,df.weight$intervention)  #SUM-CODING HERE!
df.weight$intervention
df.weight$gender
df.weight$gender <- ifelse(df.weight$gender==0,-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$gender
df.weight$gender <- ifelse(df.weight$gender==0,-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$gender
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender
df.weight$gender <- ifelse(df.weight$gender==0,-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$gender
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender
ifelse(df.weight$gender==0,-1,df.weight$gender)
ifelse(df.weight$gender==0,1,df.weight$gender)
ifelse(df.weight$gender==0,2,df.weight$gender)
ifelse(df.weight$gender==0,,df.weight$gender)
ifelse(df.weight$gender==0)
(df.weight$gender==0)
ifelse(df.weight$gender==0,4,df.weight$gender)
df.weight$intervention
df.weight$intervention <- ifelse(df.weight$intervention==0,-1,df.weight$intervention)  #SUM-CODING HERE!
df.weight$intervention
df.weight$gender <- ifelse(df.weight$gender=="0",1,-1)  #SUM-CODING HERE!
df.weight$gender
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender <- ifelse(df.weight$gender=="0",1,-1)  #SUM-CODING HERE!
df.weight$gender
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
df.weight
df.weight$gender <- ifelse(df.weight$gender==0,-1,df.weight$gender)  #SUM-CODING HERE!
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight
df.weight$gender <- ifelse(df.weight$gender==0,-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$gender
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$gender
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$gender
df.weight$intervention
df.weight$intervention <- ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)  #SUM-CODING HERE!
df.weight$intervention
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$intervention <- ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)  #SUM-CODING HERE!
df.weight$intervention
df.weight$intervention
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$intervention
df.weight$intervention <- ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)  #SUM-CODING HERE!
df.weight$intervention
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$gender
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
df.weight
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,df.weight$gender)  #SUM-CODING HERE!
df.weight$intervention <- ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)  #SUM-CODING HERE!
df.weight$gender
df.weight$intervention
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$intervention
ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)
ifelse(df.weight$intervention=="Liraglutide",-1,df.weight$intervention)
ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)
ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)*-1
df.weight$intervention <- ifelse(df.weight$intervention==" Liraglutide",-1,df.weight$intervention)*-1  #SUM-CODING HERE!
df.weight$intervention
df.weight$intervention <- ifelse(df.weight$intervention=="Placebo",-1,df.weight$intervention)  #SUM-CODING HERE!
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$intervention
ifelse(df.weight$intervention=="Placebo",-1,1)
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,1)  #SUM-CODING HERE!
df.weight$intervention <- ifelse(df.weight$intervention=="Placebo",-1,1)  #SUM-CODING HERE!
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,1)  #SUM-CODING HERE!
df.weight$intervention <- ifelse(df.weight$intervention=="Placebo",-1,1)  #SUM-CODING HERE!
df.weight$gender
df.weight$intervention
#---------------------------------------------------- define statstical Model
mf = formula(BMI_diff ~ intervention + gender + age  + (1|id))
#---------------------------------------------------- run frequenstistic stat
fmod_weight = lm(update(mf, ~.- (1|id)) , data = df.weight)
anova(fmod_weight)
summary(fmod_weight)
df.weight$BMI_diff_z <- scale (db.weight$BMI_diff_z)  #SUM-CODING HERE!
df.weight$BMI_diff_z <- scale (db.weight$BMI_diff)  #SUM-CODING HERE!
db.weight
df.weight$BMI_diff_z <- scale (df.weight$BMI_diff)  #SUM-CODING HERE!
#---------------------------------------------------- define statstical Model
mf = formula(BMI_diff_z ~ intervention + gender + age  + (1|id))
#---------------------------------------------------- run frequenstistic stat
fmod_weight = lm(update(mf, ~.- (1|id)) , data = df.weight)
anova(fmod_weight)
summary(fmod_weight)
confint(fmod_weight, level = 0.95, method = "Wald")
# ----- visualize assumptions check
plot(fitted(fmod_weight),residuals(fmod_weight))
qqnorm(residuals(fmod_weight))
hist(residuals(fmod_weight))
#---------------------------------------------------- run baysian stat
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 40000
#---------------------------------------------------- run baysian stat
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 40000
bmod_weight = brm(BMI_diff_z ~ intervention + gender + age, data=df.weight, family = gaussian,
prior = c(prior(normal(0,1), class = "b")),
sample_prior=TRUE, chains=4,
iter=niter, warmup=1000, seed=123, backend="cmdstanr",
control = list(adapt_delta = 0.99))
bmod_weight
# save model so that we do not have to run it evertime
save (bmod_weight, file = file.path(analysis_path, 'Bmod_weight.R'))
# extract BF
full_tab_weight = describe_posterior(bmod_weight, estimate = "median",
dispersion = T, ci = .9, ci_method = "hdi",
bf_prior = bmod_weight, diagnostic = "Rhat",
test = c("p_direction", "bf"))
full_tab_weight
HED.trial$saturation = scales::rescale(as.numeric(HED.trial$trialxcondition), to = c(19,-19))
HED.trial$perceived_liking_z = scale(HED.trial$perceived_liking) # so that the prior are scaled correctly
HED.trial$perceived_liking_z = scale(HED.trial$perceived_liking) # so that the prior are scaled correctly
HED.trial$intervention
HED.trial
HED.trial$intervention
factor(HED.trial$intervention)
HED.trial <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$trialxcondition, ALL$condition, ALL$session, ALL$intervention), FUN='mean') # extract means
colnames(HED.trial) <- c('id',"trialxcondition",'condition',"session","intervention","perceived_liking")
HED.trial
HED.trial$intervention
df.weight$intervention
df.weight$intervention <- factor(ifelse(df.weight$intervention=="Placebo",-1,1))  #SUM-CODING HERE!
df.weight$intervention
# ---------------------------------------------------  define database
df.weight <- aggregate(ALL$BMI_diff, by = list(ALL$id, ALL$gender, ALL$age, ALL$intervention), FUN='mean', na.rm = T) # extract means
colnames(df.weight) <- c('id','gender','age', 'intervention','BMI_diff')
df.weight$gender <- ifelse(df.weight$gender=="Male",-1,1)  #SUM-CODING HERE!
df.weight$intervention <- factor(ifelse(df.weight$intervention=="Placebo",-1,1))  #SUM-CODING HERE!
df.weight$intervention
df.weight$BMI_diff_z <- scale (df.weight$BMI_diff)  #SUM-CODING HERE!
#---------------------------------------------------- define statstical Model
mf = formula(BMI_diff_z ~ intervention + gender + age  + (1|id))
#---------------------------------------------------- run frequenstistic stat
fmod_weight = lm(update(mf, ~.- (1|id)) , data = df.weight)
anova(fmod_weight)
summary(fmod_weight)
confint(fmod_weight, level = 0.95, method = "Wald")
# ----- visualize assumptions check
plot(fitted(fmod_weight),residuals(fmod_weight))
qqnorm(residuals(fmod_weight))
hist(residuals(fmod_weight))
#---------------------------------------------------- run baysian stat
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 40000
bmod_weight = brm(BMI_diff_z ~ intervention + gender + age, data=df.weight, family = gaussian,
prior = c(prior(normal(0,1), class = "b")),
sample_prior=TRUE, chains=4,
iter=niter, warmup=1000, seed=123, backend="cmdstanr",
control = list(adapt_delta = 0.99))
bmod_weight
# save model so that we do not have to run it evertime
save (bmod_weight, file = file.path(analysis_path, 'Bmod_weight.R'))
# extract BF
full_tab_weight = describe_posterior(bmod_weight, estimate = "median",
dispersion = T, ci = .9, ci_method = "hdi",
bf_prior = bmod_weight, diagnostic = "Rhat",
test = c("p_direction", "bf"))
full_tab_weight
ifelse(HED.trial$intervention=="Placebo",-1,1)
factor(ifelse(HED.trial$intervention=="Placebo",-1,1) )
HED.trial$intervention <- factor(ifelse(HED.trial$intervention=="Placebo",-1,1))  #SUM-CODING HERE!
mf = formula(perceived_liking_z ~ condition*session*intervention*saturation + (condition*session*saturation|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.trial, control = my_control)
anova(fmod_like,type=2)
summary(fmod_like)
HED.trial <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$trialxcondition, ALL$condition, ALL$session, ALL$intervention), FUN='mean') # extract means
colnames(HED.trial) <- c('id',"trialxcondition",'condition',"session","intervention","perceived_liking")
HED.trial$saturation = scales::rescale(as.numeric(HED.trial$trialxcondition), to = c(19,-19))
HED.trial$perceived_liking_z = scale(HED.trial$perceived_liking) # so that the prior are scaled correctly
mf = formula(perceived_liking_z ~ condition*session*intervention*saturation + (condition*session*saturation|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.trial, control = my_control)
anova(fmod_like,type=2)
HED.trial$condition
HED.trial$session
HED.trial$intervention_sc <- factor(ifelse(HED.trial$intervention=="Placebo",-1,1))  #SUM-CODING HERE!
HED.trial$condition_sc <- factor(ifelse(HED.trial$condition=="Empty",-1,1))  #SUM-CODING HERE!
HED.trial$session_sc <- factor(ifelse(HED.trial$session=="second",-1,1))  #SUM-CODING HERE!
mf = formula(perceived_liking_z ~ condition_sc*session_sc*intervention_sc*saturation + (condition_sc*session_sc*saturation|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.trial, control = my_control)
anova(fmod_like,type=2)
summary(fmod_like)
#---------------------------------------------------- run baysian stat
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 40000
my_stanvars <- stanvar(scode = stan_funs, block = "functions")
bmod_like = brm(bf(perceived_liking_z ~ condition_sc*session_sc*intervention_sc*scale(saturation) + (condition_sc*session_sc*scale(saturation)|id), hu~1),
family = hurdle_gaussian,
stanvars = stanvars,
data=HED.trial,
prior =  c(prior(normal(0,1), class="b", coef=""),prior(student_t(3,0,5), class="sd")),
sample_prior=TRUE,
chains = 4,
iter = 2000,
warmup = 500,
seed = 123,
backend = "cmdstan",
control = list(adapt_delta = 0.99))
full_tab_like
full_tab_like = describe_posterior(bmod_like, estimate = "median", dispersion = T,
ci = .9, ci_method = "hdi",
bf_prior = bmod_like, diagnostic = "Rhat",
test = c("p_direction", "bf"))
full_tab_like
summary(fmod_weight)
confint(fmod_weight, level = 0.95, method = "Wald")
full_tab_weight
summary(fmod_like)
full_tab_like
confint(fmod_like, level = 0.95, method = "Wald")
HED.means
HED.supp <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$condition, ALL$session, ALL$intervention, ALL$BMI_diff), FUN='mean', na.rm = T) # extract means
colnames(HED.supp) <- c('id','condition','session', 'intervention','BMI_diff',perceived_liking')
mf = formula(perceived_liking_z ~ condition*session*intervention*BMI_diff+ (condition*session*intervetion|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.supp, control = my_control)
anova(fmod_like,type=2)
)
)
)
)))))))
mf = formula(perceived_liking ~ condition*session*intervention*BMI_diff+ (condition*session*intervetion|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.supp, control = my_control)
HED.supp
HED.supp <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$condition, ALL$session, ALL$intervention, ALL$BMI_diff), FUN='mean', na.rm = T) # extract means
colnames(HED.supp) <- c('id','condition','session', 'intervention','BMI_diff','perceived_liking')
mf = formula(perceived_liking ~ condition*session*intervention*BMI_diff+ (condition*session*intervetion|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.supp, control = my_control)
HED.supp
mf = formula(perceived_liking ~ condition*session*intervention*BMI_diff+ (condition*session*intervention|id))
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = HED.supp, control = my_control)
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = ALL, control = my_control)
#---------------------------------------------------- run frequenstistic stat
fmod_like = lmer(mf, data = ALL, control = my_control)
anova(fmod_like,type=2)
summary(fmod_like)
HED.supp
HED.supp <- ddply(HED.supp, .(id), transform, liking_diff  = perceived_liking,[CS=="second"] - perceived_liking[CS=="third"])
HED.supp <- ddply(HED.supp, .(id), transform, liking_diff  = perceived_liking,[session=="second"] - perceived_liking[session=="third"])
HED.supp <- ddply(HED.supp, .(id), transform, liking_diff  = perceived_liking[session=="second"] - perceived_liking[session=="third"])
HED.supp
HED.supp <- subset(HED.supp, session == "third")
corr(HED.supp$BMI_diff, HED.supp$liking_diff)
cor(HED.supp$BMI_diff, HED.supp$liking_diff)
cor.plot(HED.supp$BMI_diff, HED.supp$liking_diff)
cor.rplot(HED.supp$BMI_diff, HED.supp$liking_diff)
corr.plot(HED.supp$BMI_diff, HED.supp$liking_diff)
corr.plot(HED.supp$BMI_diff, HED.supp$liking_diff)
cor.plot(HED.supp$BMI_diff, HED.supp$liking_diff)
scatterplot(HED.supp$liking_diff, HED.supp$BMI_diff)
scatterplot(HED.supp$liking_diff, HED.supp$BMI_diff)
cor.plot(HED.supp$liking_diff, HED.supp$BMI_diff)
scatterplot(HED.supp$BMI_diff, HED.supp$liking_diff)
HED.supp$liking_diff
HED.supp$BMI_diff
scatterplot(HED.supp$BMI_diff, HED.supp$liking_diff)
library(psych)
scatterplot(HED.supp$BMI_diff, HED.supp$liking_diff)
pacman::p_load(car, lme4, lmerTest, pbkrtest, ggplot2, dplyr, plyr, tidyr, multcomp, mvoutlier, HH, doBy, psych, pastecs, reshape, reshape2,
jtools, effects, compute.es, DescTools, MBESS, afex, ez, metafor, influence.ME, longpower,pwr,sjstats,flexmix,GPArotation)
scatterplot(HED.supp$BMI_diff, HED.supp$liking_diff)
HED.supp <- subset(HED.supp, condition == "chocolate")
scatterplot(HED.supp$BMI_diff, HED.supp$liking_diff)
HED.supp <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$condition, ALL$session, ALL$intervention, ALL$BMI_diff), FUN='mean', na.rm = T) # extract means
colnames(HED.supp) <- c('id','condition','session', 'intervention','BMI_diff','perceived_liking')
HED.supp <- ddply(HED.supp, .(id), transform, liking_diff  = perceived_liking[session=="second"] - perceived_liking[session=="third"])
HED.supp <- subset(HED.supp, session == "third")
HED.supp <- subset(HED.supp, condition == "chocolate")
HED.supp <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$condition, ALL$session, ALL$intervention, ALL$BMI_diff), FUN='mean', na.rm = T) # extract means
colnames(HED.supp) <- c('id','condition','session', 'intervention','BMI_diff','perceived_liking')
HED.supp <- ddply(HED.supp, .(id), transform, liking_diff  = perceived_liking[session=="second"] - perceived_liking[session=="third"])
HED.supp <- subset(HED.supp, session == "third")
HED.supp
HED.supp <- subset(HED.supp, condition == "MilkShake")
scatterplot(HED.supp$BMI_diff, HED.supp$liking_diff)
HED.supp <- aggregate(ALL$perceived_liking, by = list(ALL$id, ALL$condition, ALL$session, ALL$intervention, ALL$BMI_diff), FUN='mean', na.rm = T) # extract means
colnames(HED.supp) <- c('id','condition','session', 'intervention','BMI_diff','perceived_liking')
HED.supp <- ddply(HED.supp, .(id), transform, liking_diff  = perceived_liking[session=="second"] - perceived_liking[session=="third"])
HED.supp <- subset(HED.supp, session == "third")
HED.choco <- subset(HED.supp, condition == "MilkShake")
scatterplot(HED.choco$BMI_diff, HED.choco$liking_diff)
cor.test(HED.choco$BMI_diff, HED.choco$liking_diff)
summary(fmod_like)
HED.supp
HED.neutral <- subset(HED.supp, condition == "Empty")
scatterplot(HED.neutral$BMI_diff, HED.neutral$liking_diff)
cor.test(HED.neutral$BMI_diff, HED.neutral$liking_diff)
cor.test(HED.choco$BMI_diff, HED.choco$liking_diff)
summary(fmod_like)
